{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaGho/reasoning_multimodal_LLMs/blob/main/vllm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuJtYzclavpw"
      },
      "outputs": [],
      "source": [
        "# !pip install qwen_vl_utils\n",
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "import torch\n",
        "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
        "from qwen_vl_utils import process_vision_info\n",
        "from datasets import load_dataset  # Assuming the GMS8k dataset is HuggingFace-compatible\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute = True\n",
        "\n",
        "# Check device compatibility\n",
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "\n",
        "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
        "dataset_name = \"deepcs233/Visual-CoT\"\n",
        "file_name = f\"data/output/{dataset_name.split('/')[-1]}_{model_name.split('/')[-1]}.csv\"\n",
        "# Load the model\n",
        "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float32 if device == \"cpu\" else torch.bfloat16,\n",
        "    device_map=None\n",
        ")\n",
        "\n",
        "# Initialize processor\n",
        "min_pixels = 256 * 28 * 28\n",
        "max_pixels = 1280 * 28 * 28\n",
        "processor = AutoProcessor.from_pretrained(model_name, min_pixels=min_pixels, max_pixels=max_pixels)\n",
        "\n"
      ],
      "metadata": {
        "id": "O5TipJ5Ofzm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataset_test = load_dataset(\"MathLLMs/MathVision\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2GvQwFRDf1ud"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test[0]"
      ],
      "metadata": {
        "id": "sAfoPaBNjL1f",
        "outputId": "eedc5799-b48c-4cdf-d5e9-73ecfd0edf1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '1',\n",
              " 'question': 'Which number should be written in place of the question mark?\\n<image1>',\n",
              " 'options': [],\n",
              " 'image': 'images/1.jpg',\n",
              " 'decoded_image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1176x178>,\n",
              " 'answer': '60',\n",
              " 'solution': None,\n",
              " 'level': 2,\n",
              " 'subject': 'arithmetic'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(input):\n",
        "    image_path = f\"{img_folder_path}/{input['image']}\"\n",
        "    prompt = input[\"question\"]\n",
        "\n",
        "    # Prepare input\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": image_path}, {\"type\": \"text\", \"text\": prompt}]}\n",
        "    ]\n",
        "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    image_inputs, video_inputs = process_vision_info(messages)\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        videos=video_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    # Move inputs to the device\n",
        "    inputs = inputs.to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Perform inference\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=256)\n",
        "\n",
        "    output_text = processor.batch_decode(\n",
        "        generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "    )[0]\n",
        "\n",
        "    # Store results\n",
        "    return {\n",
        "        \"prompt\": prompt, \"generated_text\": output_text\n",
        "      }\n",
        "\n",
        "\n",
        "dataset_test = pd.DataFrame(dataset_test)\n",
        "# Iterate over dataset\n",
        "dataset_test[[\"prompt\", \"generated_text\"]] = dataset_test.apply(generate_answer, axis=1, result_type=\"expand\")\n",
        "\n"
      ],
      "metadata": {
        "id": "MK3w-7def3Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def final_answer(text: str):\n",
        "    text = text.lower()\n",
        "    if 'answer is' not in text:\n",
        "        return np.nan\n",
        "    return text.split('answer is:').strip().replace('$', '')\n",
        "# Example metric: String matching (very basic)\n",
        "ground_truths = [result[\"ground_truth\"] for result in results]\n",
        "generated_texts = [final_answer(result[\"generated_text\"]) for result in results]\n",
        "exact_matches = [gt == gen for gt, gen in zip(ground_truths, generated_texts)]\n",
        "accuracy = sum(exact_matches) / len(exact_matches)\n",
        "\n",
        "print(f\"Exact Match Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Optionally save results\n",
        "import json\n",
        "with open(\"evaluation_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=4)"
      ],
      "metadata": {
        "id": "-rllWWvjk4Mm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}