{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from datasets import load_dataset  # Assuming the GMS8k dataset is HuggingFace-compatible\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "compute = True\n",
    "\n",
    "# Check device compatibility\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "dataset_name = \"deepcs233/Visual-CoT\"\n",
    "file_name = f\"data/output/{dataset_name.split('/')[-1]}_{model_name.split('/')[-1]}.csv\"\n",
    "# Load the model\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float32 if device == \"cpu\" else torch.bfloat16,\n",
    "    device_map=None\n",
    ")\n",
    "\n",
    "# Initialize processor\n",
    "min_pixels = 256 * 28 * 28\n",
    "max_pixels = 1280 * 28 * 28\n",
    "processor = AutoProcessor.from_pretrained(model_name, min_pixels=min_pixels, max_pixels=max_pixels)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"Graphcore/vqa\", split=\"validation[:50]\", trust_remote_code=True, download_mode=\"force_redownload\")\n",
    "\n",
    "# Evaluation storage\n",
    "results = []\n",
    "\n",
    "if compute:\n",
    "    # Iterate over dataset\n",
    "    for sample in tqdm(dataset):\n",
    "        image_path = None  # Adjust key to match GMS8k format\n",
    "        prompt = sample[\"question\"]    # Adjust key to match GMS8k format\n",
    "        answer = sample[\"answer\"]\n",
    "        ground_truth = answer.split('#### ')[1]\n",
    "        \n",
    "\n",
    "        # Prepare input\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]} # {\"type\": \"image\", \"image\": image_path}, \n",
    "        ]\n",
    "        text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Move inputs to the device\n",
    "        inputs = inputs.to(device)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Perform inference\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=256)\n",
    "        # generated_ids_trimmed = [\n",
    "        #     out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        # ]\n",
    "\n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )[0]\n",
    "\n",
    "        # Store results\n",
    "        results.append({\"image\": image_path, \"prompt\": prompt, \"generated_text\": output_text, \"ground_truth\": ground_truth})\n",
    "\n",
    "    pd.DataFrame(results).to_csv(file_name)\n",
    "else:\n",
    "    results = pd.read_csv(file_name)\n",
    "\n",
    "def final_answer(text: str):\n",
    "    text = text.lower()\n",
    "    if 'answer is' not in text:\n",
    "        return np.nan\n",
    "    return text.split('answer is:').strip().replace('$', '')\n",
    "# Example metric: String matching (very basic)\n",
    "ground_truths = [result[\"ground_truth\"] for result in results]\n",
    "generated_texts = [final_answer(result[\"generated_text\"]) for result in results]\n",
    "exact_matches = [gt == gen for gt, gen in zip(ground_truths, generated_texts)]\n",
    "accuracy = sum(exact_matches) / len(exact_matches)\n",
    "\n",
    "print(f\"Exact Match Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Optionally save results\n",
    "import json\n",
    "with open(\"evaluation_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
