{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nq8Fz3QLE7hV",
        "outputId": "005557a8-25ea-4c78-d903-6aff62a67ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "fatal: destination path 'reasoning_multimodal_LLMs' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/NaGho/reasoning_multimodal_LLMs.git\n",
        "import sys\n",
        "sys.path.append('/content/reasoning_multimodal_LLMs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "fcc12015c54d4fd79815289b2eb4e940",
            "6c61423d841b4473a0c3247908a68541",
            "17036ae254124c11b779595100c8e504",
            "0b2cd8caf1534552b7d680b529830760",
            "4722f2703ed0475384bbf3a68787cb07",
            "b5ec38c6b02e4e438e9ff0f94b90404a",
            "f1338004c43c40dc9410d7b665b9f913",
            "a452dfa7c008441d933ba43fac1d2054",
            "4f6ab5f094e049cdbb69a653621a22d0",
            "e7467a8745fc48ff84057643fc46f639",
            "d9ac7c1d6ef34203a5e2fdadc3e5c866"
          ]
        },
        "id": "Kkj4BM_Z6znC",
        "outputId": "5813c64a-ed3f-459d-bb99-437fdad67e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute_dtype =  torch.bfloat16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcc12015c54d4fd79815289b2eb4e940"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading processor from llava-hf/llava-1.5-7b-hf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer from llava-hf/llava-1.5-7b-hf\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.45.2\n",
        "!pip install accelerate\n",
        "!pip install deepspeed==0.14.4\n",
        "!pip install av\n",
        "!pip install peft\n",
        "# !pip install --force-reinstall -U bitsandbytes\n",
        "!pip uninstall bitsandbytes -y\n",
        "!pip install --no-cache-dir bitsandbytes\n",
        "!pip install flash-attn #--no-build-isolation\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_PROJECT\"]= \"vlmms-ft\"\n",
        "from dataclasses import asdict\n",
        "import math\n",
        "from pathlib import Path\n",
        "from typing import List, Optional\n",
        "import yaml\n",
        "\n",
        "from accelerate.utils import DistributedType\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import Trainer, deepspeed\n",
        "# import deepspeed\n",
        "\n",
        "from arguments import ModelArguments, DataArguments, TrainingArguments, LoraArguments\n",
        "from collators import COLLATORS\n",
        "from loaders import LOADERS\n",
        "from supported_models import MODULE_KEYWORDS\n",
        "from utils import (\n",
        "    rank0_print, find_all_linear_names, safe_save_model_for_hf_trainer,\n",
        "    get_peft_state_maybe_zero_3, TrainerWithCustomSampler\n",
        ")\n",
        "from my_datasets import MySupervisedDataset\n",
        "\n",
        "# def train():\n",
        "parser = transformers.HfArgumentParser(\n",
        "    (ModelArguments, DataArguments, TrainingArguments, LoraArguments)\n",
        ")\n",
        "default_args = [\n",
        "    \"--output_dir\", \"/content/drive/MyDrive/reasoning_multimodal_LLMs/fine_tuned\",\n",
        "]\n",
        "model_args, data_args, training_args, lora_args = parser.parse_args_into_dataclasses(default_args)\n",
        "\n",
        "# data_args.data_path = \"/content/drive/MyDrive/reasoning_multimodal_LLMs/example_data/mathvisionVistaMerged_train.json\" # mathvision_train\n",
        "# data_args.image_folder = \"/content/drive/MyDrive/MATH-V-main/images\"\n",
        "\n",
        "data_args.data_path = \"/content/drive/MyDrive/MathV360K_images/MathV360K_train_pruned.json\"\n",
        "data_args.image_folder = \"/content/drive/MyDrive/MathV360K_images\"\n",
        "\n",
        "# data_args.eval_data_path = \"/content/reasoning_multimodal_LLMs/example_data/mathvision_val.json\"\n",
        "\n",
        "training_args.fp16 = False\n",
        "training_args.bf16 = True\n",
        "training_args.bf16_full_eval = True\n",
        "training_args.per_device_train_batch_size = 2\n",
        "training_args.per_device_eval_batch_size = 2\n",
        "training_args.gradient_accumulation_steps = 4\n",
        "training_args.gradient_checkpointing = True\n",
        "training_args.num_train_epochs = 5\n",
        "training_args.ddp_timeout = 750000\n",
        "training_args.resume_from_checkpoint = f\"{training_args.output_dir}/checkpoint-1500\" # True #\n",
        "# training_args.load_best_model_at_end = True\n",
        "\n",
        "# dumping arguments\n",
        "output_dir = getattr(training_args, 'output_dir', None)\n",
        "assert output_dir is not None, \"output_dir is required\"\n",
        "args_dir = Path(output_dir) / \"arguments\"\n",
        "args_dir.mkdir(parents=True, exist_ok=True)\n",
        "yaml.dump(asdict(model_args), open(args_dir / \"model.yaml\", \"w\"))\n",
        "yaml.dump(asdict(data_args), open(args_dir / \"data.yaml\", \"w\"))\n",
        "yaml.dump(asdict(training_args), open(args_dir / \"training.yaml\", \"w\"))\n",
        "yaml.dump(asdict(lora_args), open(args_dir / \"lora.yaml\", \"w\"))\n",
        "\n",
        "compute_dtype = (torch.float16 if training_args.fp16 else (torch.bfloat16 if training_args.bf16 else torch.float32))\n",
        "print(\"compute_dtype = \", compute_dtype)\n",
        "if getattr(training_args, 'deepspeed', None) and getattr(lora_args, 'q_lora', False):\n",
        "    rank0_print(\"Distributed Deepspeed Enabled...\")\n",
        "    training_args.distributed_state.distributed_type = DistributedType.DEEPSPEED\n",
        "\n",
        "device_map = None\n",
        "if lora_args.q_lora:\n",
        "    device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)} if int(os.environ.get(\"WORLD_SIZE\", 1)) != 1 else None\n",
        "    if len(training_args.fsdp) > 0 or deepspeed.is_deepspeed_zero3_enabled():\n",
        "        raise ValueError(\"FSDP or ZeRO3 are not incompatible with QLoRA.\")\n",
        "\n",
        "# llm quantization config (for q-lora)\n",
        "bnb_config = None\n",
        "if lora_args.use_lora and lora_args.q_lora:\n",
        "    from transformers import BitsAndBytesConfig\n",
        "    rank0_print(\"Quantization for LLM enabled...\")\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "    )\n",
        "\n",
        "# load model, tokenizer, processor\n",
        "rank0_print(\"Loading model, tokenizer, processor...\")\n",
        "\n",
        "loader = LOADERS[model_args.model_family_id](\n",
        "    model_hf_path=model_args.model_hf_path,\n",
        "    model_local_path=model_args.model_local_path,\n",
        "    compute_dtype=compute_dtype,\n",
        "    bnb_config=bnb_config,\n",
        "    use_flash_attn=training_args.use_flash_attn,\n",
        "    device_map=device_map,\n",
        ")\n",
        "model, tokenizer, processor, config = loader.load()\n",
        "tokenizer.model_max_length = training_args.model_max_length\n",
        "\n",
        "if training_args.gradient_checkpointing:\n",
        "    model.enable_input_require_grads()\n",
        "\n",
        "# freeze certain params\n",
        "vision_encoder_keys = MODULE_KEYWORDS[model_args.model_family_id][\"vision_encoder\"]\n",
        "if not training_args.train_vision_encoder:\n",
        "    rank0_print(f\"Vision encoder is freezed... including:\")\n",
        "    for module in vision_encoder_keys:\n",
        "        rank0_print(f\"\\t{module}\")\n",
        "        eval(f\"model.{module}\").requires_grad_(False)\n",
        "\n",
        "vision_projector_keys = MODULE_KEYWORDS[model_args.model_family_id][\"vision_projector\"]\n",
        "if not training_args.train_vision_projector:\n",
        "    rank0_print(f\"Vision projector is freezed... including:\")\n",
        "    for module in vision_projector_keys:\n",
        "        rank0_print(f\"\\t{module}\")\n",
        "        eval(f\"model.{module}\").requires_grad_(False)\n",
        "\n",
        "# other components preparation (e.g., image_newline, vision_resampler)\n",
        "# we will just freeze these\n",
        "if \"others\" in MODULE_KEYWORDS[model_args.model_family_id]:\n",
        "    rank0_print(f\"Other multimodal component is freezed... including:\")\n",
        "    for other_key in MODULE_KEYWORDS[model_args.model_family_id][\"others\"]:\n",
        "        rank0_print(f\"\\t{other_key}\")\n",
        "        eval(f\"model.{other_key}\").requires_grad_(False)\n",
        "\n",
        "# lora preparation\n",
        "llm_keys = MODULE_KEYWORDS[model_args.model_family_id][\"llm\"]\n",
        "if not (lora_args.use_lora or (training_args.train_vision_encoder and lora_args.use_vision_lora)):\n",
        "    rank0_print(\"No LoRA enabled...\")\n",
        "else:\n",
        "    named_modules = {n: m for n, m in model.named_modules()}\n",
        "    lora_modules = []\n",
        "    full_modules = []\n",
        "\n",
        "    if training_args.train_vision_encoder and lora_args.use_vision_lora:\n",
        "        rank0_print(\"LoRA for vision encoder enabled...\")\n",
        "        lora_modules.extend(find_all_linear_names(named_modules, vision_encoder_keys))\n",
        "    elif training_args.train_vision_encoder:\n",
        "        rank0_print(\"Vision encoder will be fully trained...\")\n",
        "        full_modules.extend(vision_encoder_keys)\n",
        "\n",
        "    if lora_args.use_lora:\n",
        "        rank0_print(\"LoRA for LLM enabled...\")\n",
        "        lora_modules.extend(find_all_linear_names(named_modules, llm_keys))\n",
        "    else:\n",
        "        rank0_print(\"LLM will be fully trained...\")\n",
        "        full_modules.extend(llm_keys)\n",
        "\n",
        "    if training_args.train_vision_projector:\n",
        "        rank0_print(\"Vision projector will be fully trained...\")\n",
        "        full_modules.extend(vision_projector_keys)\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=lora_args.lora_r,\n",
        "        lora_alpha=lora_args.lora_alpha,\n",
        "        target_modules=lora_modules,\n",
        "        modules_to_save=full_modules,\n",
        "        lora_dropout=lora_args.lora_dropout,\n",
        "        bias=lora_args.lora_bias,\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "\n",
        "    if lora_args.q_lora:\n",
        "        model = prepare_model_for_kbit_training(\n",
        "            model, use_gradient_checkpointing=training_args.gradient_checkpointing\n",
        "        )\n",
        "\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model = model.to(compute_dtype)\n",
        "\n",
        "# print trainable parameters for inspection\n",
        "rank0_print(\"Trainable parameters:\")\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        rank0_print(f\"\\t{name}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TIGOccYyIhuu",
        "outputId": "3598c4c4-ed54-4325-af30-b77912b99f2c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training_args = \n",
            "  TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=True,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=750000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/reasoning_multimodal_LLMs/fine_tuned/runs/Feb24_19-11-49_48e98ccfb821,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "mask_question_tokens=True,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "model_max_length=1024,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/content/drive/MyDrive/reasoning_multimodal_LLMs/fine_tuned,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=2,\n",
            "per_device_train_batch_size=2,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=/content/drive/MyDrive/reasoning_multimodal_LLMs/fine_tuned/checkpoint-1500,\n",
            "run_name=/content/drive/MyDrive/reasoning_multimodal_LLMs/fine_tuned,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "train_vision_encoder=False,\n",
            "train_vision_projector=False,\n",
            "use_cpu=False,\n",
            "use_flash_attn=True,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1078' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1078/6250 1:09:12 < 5:32:38, 0.26 it/s, Epoch 0.86/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.664900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.557400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2519' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2519/6250 2:36:00 < 3:51:15, 0.27 it/s, Epoch 2.01/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.664900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.557400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.511500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.490000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.480600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6808f5178ff8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m )\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2052\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2053\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2388\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3516\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3518\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2246\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# load data\n",
        "rank0_print(\"Loading data...\")\n",
        "train_dataset = MySupervisedDataset(\n",
        "    data_path=data_args.data_path,\n",
        "    image_folder=data_args.image_folder,\n",
        "    video_folder=data_args.video_folder,\n",
        "    num_frames=data_args.num_frames,\n",
        "    model_family_id=model_args.model_family_id,\n",
        "    user_key=data_args.user_key,\n",
        "    assistant_key=data_args.assistant_key\n",
        ")\n",
        "if data_args.eval_data_path:\n",
        "    eval_dataset = MySupervisedDataset(\n",
        "        data_path=data_args.eval_data_path,\n",
        "        image_folder=data_args.image_folder,\n",
        "        video_folder=data_args.video_folder,\n",
        "        num_frames=data_args.num_frames,\n",
        "        model_family_id=model_args.model_family_id,\n",
        "        user_key=data_args.user_key,\n",
        "        assistant_key=data_args.assistant_key\n",
        "    )\n",
        "else:\n",
        "    eval_dataset = None\n",
        "    training_args.eval_strategy = \"no\"\n",
        "\n",
        "# data collator\n",
        "data_collator = COLLATORS[model_args.model_family_id](\n",
        "    config=config,\n",
        "    tokenizer=tokenizer,\n",
        "    processor=processor,\n",
        "    mask_question_tokens=training_args.mask_question_tokens\n",
        ")\n",
        "print('training_args = \\n ', training_args)\n",
        "# trainer\n",
        "trainer = TrainerWithCustomSampler(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "trainer.train()\n",
        "trainer.save_state()\n",
        "\n",
        "safe_save_model_for_hf_trainer(trainer=trainer, output_dir=output_dir)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.1 (main, Dec  3 2024, 17:59:52) [Clang 16.0.0 (clang-1600.0.26.4)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a705a04fb367ec22af69d2ff9887b181893499ca251cf5bc866022978b76dc8e"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fcc12015c54d4fd79815289b2eb4e940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c61423d841b4473a0c3247908a68541",
              "IPY_MODEL_17036ae254124c11b779595100c8e504",
              "IPY_MODEL_0b2cd8caf1534552b7d680b529830760"
            ],
            "layout": "IPY_MODEL_4722f2703ed0475384bbf3a68787cb07"
          }
        },
        "6c61423d841b4473a0c3247908a68541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5ec38c6b02e4e438e9ff0f94b90404a",
            "placeholder": "​",
            "style": "IPY_MODEL_f1338004c43c40dc9410d7b665b9f913",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "17036ae254124c11b779595100c8e504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a452dfa7c008441d933ba43fac1d2054",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f6ab5f094e049cdbb69a653621a22d0",
            "value": 3
          }
        },
        "0b2cd8caf1534552b7d680b529830760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7467a8745fc48ff84057643fc46f639",
            "placeholder": "​",
            "style": "IPY_MODEL_d9ac7c1d6ef34203a5e2fdadc3e5c866",
            "value": " 3/3 [00:11&lt;00:00,  3.85s/it]"
          }
        },
        "4722f2703ed0475384bbf3a68787cb07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ec38c6b02e4e438e9ff0f94b90404a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1338004c43c40dc9410d7b665b9f913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a452dfa7c008441d933ba43fac1d2054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f6ab5f094e049cdbb69a653621a22d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7467a8745fc48ff84057643fc46f639": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9ac7c1d6ef34203a5e2fdadc3e5c866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}